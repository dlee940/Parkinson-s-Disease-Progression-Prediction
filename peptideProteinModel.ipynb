{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlee940/Parkinson-s-Disease-Progression-Prediction/blob/main/peptideProteinModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxeKcG5vWvy0"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poScCsn377nx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #python data analysis library\n",
        "import numpy as np #best for working with arrays!\n",
        "import matplotlib.pyplot as plt #Plotting/viz library\n",
        "import seaborn as sns #data viz library based on matplotlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,precision_score,recall_score,classification_report, accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykZRjOANXZHH"
      },
      "source": [
        "# **Reading Data from Source**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwyme60dADf3",
        "outputId": "aa46d272-2605-4951-ffdc-5056e1104a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zmXDt-oAepU"
      },
      "outputs": [],
      "source": [
        "# Change based on whether using Kaggle or Google Drive\n",
        "patientPath = \"/content/drive/MyDrive/Parkinsons/Subteam 3 Spring 2023/Kaggle Competition Spring 23/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\"\n",
        "peptidePath = \"/content/drive/MyDrive/Parkinsons/Subteam 3 Spring 2023/Kaggle Competition Spring 23/amp-parkinsons-disease-progression-prediction/train_peptides.csv\"\n",
        "proteinPath = \"/content/drive/MyDrive/Parkinsons/Subteam 3 Spring 2023/Kaggle Competition Spring 23/amp-parkinsons-disease-progression-prediction/train_proteins.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcvSdQ4TA9Cp"
      },
      "outputs": [],
      "source": [
        "proteins = pd.read_csv(proteinPath)\n",
        "peptides = pd.read_csv(peptidePath)\n",
        "clinical = pd.read_csv(patientPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp2-t4R4LeJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e2557f-f5f6-461a-fff6-8ff6dece67e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proteins shape:              (232741, 5)\n",
            "peptides shape:              (981834, 6)\n",
            "clinical shape:              (2615, 8)\n"
          ]
        }
      ],
      "source": [
        "print('proteins shape:             ', proteins.shape)\n",
        "print('peptides shape:             ', peptides.shape)\n",
        "print('clinical shape:             ', clinical.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OvmMgxsXfNW"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjvyJJJadpxc"
      },
      "outputs": [],
      "source": [
        "df_0_1 = clinical[(clinical.visit_month == 3)][['visit_id','updrs_1']]\n",
        "df_0_2 = clinical[(clinical.visit_month == 3)][['visit_id','updrs_2']]\n",
        "df_0_3 = clinical[(clinical.visit_month == 3)][['visit_id','updrs_3']]\n",
        "df_0_4 = clinical[(clinical.visit_month == 3)][['visit_id','updrs_4']]\n",
        "\n",
        "df_proteins = pd.merge(proteins, df_0_1, on = 'visit_id', how = 'inner').reset_index()\n",
        "proteins_updrs1 = df_proteins.groupby('UniProt').agg(updrs_1_sum = ('updrs_1','mean')).reset_index()\n",
        "\n",
        "df_proteins = pd.merge(proteins, df_0_2, on = 'visit_id', how = 'inner').reset_index()\n",
        "proteins_updrs2 = df_proteins.groupby('UniProt').agg(updrs_1_sum = ('updrs_2','mean')).reset_index()\n",
        "\n",
        "df_proteins = pd.merge(proteins, df_0_3, on = 'visit_id', how = 'inner').reset_index()\n",
        "proteins_updrs3 = df_proteins.groupby('UniProt').agg(updrs_1_sum = ('updrs_3','mean')).reset_index()\n",
        "\n",
        "df_proteins = pd.merge(proteins, df_0_4, on = 'visit_id', how = 'inner').reset_index()\n",
        "proteins_updrs4 = df_proteins.groupby('UniProt').agg(updrs_1_sum = ('updrs_4','mean')).reset_index()\n",
        "\n",
        "df_peptides_ab = pd.merge(peptides, df_0_1, on = 'visit_id', how = 'inner').reset_index()\n",
        "peptides_updrs1 = df_peptides_ab.groupby('Peptide').agg(updrs_1_sum = ('updrs_1','mean')).reset_index()\n",
        "\n",
        "df_peptides_ab = pd.merge(peptides, df_0_2, on = 'visit_id', how = 'inner').reset_index()\n",
        "peptides_updrs2 = df_peptides_ab.groupby('Peptide').agg(updrs_1_sum = ('updrs_2','mean')).reset_index()\n",
        "\n",
        "df_peptides_ab = pd.merge(peptides, df_0_3, on = 'visit_id', how = 'inner').reset_index()\n",
        "peptides_updrs3 = df_peptides_ab.groupby('Peptide').agg(updrs_1_sum = ('updrs_3','mean')).reset_index()\n",
        "\n",
        "df_peptides_ab = pd.merge(peptides, df_0_4, on = 'visit_id', how = 'inner').reset_index()\n",
        "peptides_updrs4 = df_peptides_ab.groupby('Peptide').agg(updrs_1_sum = ('updrs_4','mean')).reset_index()\n",
        "\n",
        "df_proteins_fts = [proteins_updrs1, proteins_updrs2, proteins_updrs3, proteins_updrs4]\n",
        "df_peptides_fts = [peptides_updrs1, peptides_updrs2, peptides_updrs3, peptides_updrs4]\n",
        "df_lst = [df_0_1, df_0_2, df_0_3, df_0_4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmn4hgIGU3IH"
      },
      "outputs": [],
      "source": [
        "def features(df, proteins, peptides, classes):\n",
        "    proteins_npx_ft = proteins.groupby('visit_id').agg(NPX_min=('NPX','min'), NPX_max=('NPX','max'), NPX_mean=('NPX','mean'), NPX_std=('NPX','std'))\\\n",
        "                    .reset_index()\n",
        "    peptides_ft_ab = peptides.groupby('visit_id').agg(Abe_min=('PeptideAbundance','min'), Abe_max=('PeptideAbundance','max'),\\\n",
        "                                                                    Abe_mean=('PeptideAbundance','mean'), Abe_std=('PeptideAbundance','std'))\\\n",
        "                    .reset_index()\n",
        "\n",
        "    df_proteins = pd.merge(proteins, df_proteins_fts[classes], on = 'UniProt', how = 'left')\n",
        "    proteins_ft = df_proteins.groupby('visit_id').agg(proteins_updrs_1_min=('updrs_1_sum','min'), proteins_updrs_1_max=('updrs_1_sum','max'),\\\n",
        "                                                              proteins_updrs_1_mean=('updrs_1_sum','mean'), proteins_updrs_1_std=('updrs_1_sum','std'))\\\n",
        "                    .reset_index()\n",
        "    df_peptides = pd.merge(peptides, df_peptides_fts[classes], on = 'Peptide', how = 'left')\n",
        "    peptides_ft = df_peptides.groupby('visit_id').agg(peptides_updrs_1_min=('updrs_1_sum','min'), peptides_updrs_1_max=('updrs_1_sum','max'),\\\n",
        "                                                              peptides_updrs_1_mean=('updrs_1_sum','mean'), peptides_updrs_1_std=('updrs_1_sum','std'))\\\n",
        "                    .reset_index()\n",
        "\n",
        "    df = pd.merge(df, proteins_npx_ft, on = 'visit_id', how = 'left')\n",
        "    df = pd.merge(df, peptides_ft_ab, on = 'visit_id', how = 'left')\n",
        "    df = pd.merge(df, proteins_ft, on = 'visit_id', how = 'left')\n",
        "    df = pd.merge(df, peptides_ft, on = 'visit_id', how = 'left')\n",
        "    df = df.fillna(df.mean())\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqnDhvJDYze6"
      },
      "outputs": [],
      "source": [
        "def smape(y_true, y_pred):\n",
        "    smap = np.zeros(len(y_true))\n",
        "\n",
        "    num = np.abs(y_true - y_pred)\n",
        "    dem = ((np.abs(y_true) + np.abs(y_pred)) / 2)\n",
        "\n",
        "    pos_ind = (y_true!=0)|(y_pred!=0)\n",
        "    smap[pos_ind] = num[pos_ind] / dem[pos_ind]\n",
        "\n",
        "    return 100 * np.mean(smap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_seWk6Of4lV"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYlqB3-gYzZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20097a6d-e60a-4f0a-e16a-506e226c9b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------\n",
            "Model 1\n",
            "\n",
            "RANDOM FOREST\n",
            "{'n_estimators': 190, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n",
            "71.51256438519329\n",
            "Train smape: 70.54270917364842\n",
            "\n",
            "SVR\n",
            "{'kernel': 'poly', 'gamma': 0.721}\n",
            "71.75552241319085\n",
            "Train smape: 70.49687673978075\n",
            "--------------------------------------------------------\n",
            "Model 2\n",
            "\n",
            "RANDOM FOREST\n",
            "{'n_estimators': 154, 'min_samples_split': 7, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 50, 'bootstrap': True}\n",
            "65.41027331731007\n",
            "Train smape: 64.66225563775066\n",
            "\n",
            "SVR\n",
            "{'kernel': 'sigmoid', 'gamma': 0.4738}\n",
            "63.459527547477286\n",
            "Train smape: 62.980791845029884\n",
            "--------------------------------------------------------\n",
            "Model 3\n",
            "\n",
            "RANDOM FOREST\n",
            "{'n_estimators': 107, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 110, 'bootstrap': True}\n",
            "41.332810491238796\n",
            "Train smape: 40.96884011487353\n",
            "\n",
            "SVR\n",
            "{'kernel': 'poly', 'gamma': 0.4421}\n",
            "40.9944902746471\n",
            "Train smape: 40.73150974709668\n"
          ]
        }
      ],
      "source": [
        "model = {}\n",
        "mms = MinMaxScaler()\n",
        "n_estimators = list(range(5,200)) # number of trees in the random forest\n",
        "max_features = ['auto', 'sqrt'] # number of features in consideration at every split\n",
        "max_depth = [int(x) for x in np.linspace(10, 120, num = 12)] # maximum number of levels allowed in each decision tree\n",
        "min_samples_split = list(range(1, 12)) # minimum sample number to split a node\n",
        "min_samples_leaf = list(range(1, 12)) # minimum sample number that can be stored in a leaf node\n",
        "bootstrap = [True, False] # method used to sample data points\n",
        "kernels = ['poly','rbf','sigmoid','linear']\n",
        "gamma = ['scale', 'auto']\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "for i in range(3):\n",
        "    print('--------------------------------------------------------')\n",
        "    print('Model {0}'.format(i + 1))\n",
        "    train_0 = features(df_lst[i], proteins, peptides, i)\n",
        "    scale_col = ['NPX_min','NPX_max','NPX_mean','NPX_std', 'Abe_min', 'Abe_max', 'Abe_mean', 'Abe_std']\n",
        "    train_0[scale_col] = mms.fit_transform(train_0[scale_col])\n",
        "\n",
        "    rfc = RandomForestRegressor()\n",
        "    svr = SVR()\n",
        "\n",
        "    forest_params = [{'n_estimators': n_estimators,\n",
        "    'max_features': max_features,\n",
        "    'max_depth': max_depth,\n",
        "    'min_samples_split': min_samples_split,\n",
        "    'min_samples_leaf': min_samples_leaf,\n",
        "    'bootstrap': bootstrap}]\n",
        "    svr_params = [{'kernel': kernels, 'gamma': gamma}]\n",
        "\n",
        "    # Random Forest\n",
        "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    clf = RandomizedSearchCV(rfc, forest_params, cv = cv, scoring=make_scorer(smape), verbose = -1)\n",
        "\n",
        "    X = train_0.drop(columns = ['visit_id','updrs_{0}'.format(i + 1)], axis = 1)\n",
        "    y = train_0['updrs_{0}'.format(i + 1)].astype(np.float32)\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    print(\"\\nRANDOM FOREST\")\n",
        "    print(clf.best_params_)\n",
        "\n",
        "    print(clf.best_score_)\n",
        "    print('Train smape:',smape(train_0['updrs_{0}'.format(i + 1)], clf.predict(train_0.drop(columns = ['visit_id','updrs_{0}'.format(i + 1)], axis = 1))))\n",
        "\n",
        "    # SVR\n",
        "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    clf = RandomizedSearchCV(svr, svr_params, cv = cv, scoring=make_scorer(smape), verbose = -1)\n",
        "\n",
        "    X = train_0.drop(columns = ['visit_id','updrs_{0}'.format(i + 1)], axis = 1)\n",
        "    y = train_0['updrs_{0}'.format(i + 1)].astype(np.float32)\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    print(\"\\nSVR\")\n",
        "    print(clf.best_params_)\n",
        "\n",
        "    print(clf.best_score_)\n",
        "    print('Train smape:',smape(train_0['updrs_{0}'.format(i + 1)], clf.predict(train_0.drop(columns = ['visit_id','updrs_{0}'.format(i + 1)], axis = 1))))\n",
        "    model[i] = clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlXdPGJ-hcwI"
      },
      "outputs": [],
      "source": [
        "import amp_pd_peptide\n",
        "env = amp_pd_peptide.make_env()\n",
        "iter_test = env.iter_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbYEvWGChlPG"
      },
      "outputs": [],
      "source": [
        "def map_test(x):\n",
        "    updrs = x.split('_')[2] + '_' + x.split('_')[3]\n",
        "    month = int(x.split('_plus_')[1].split('_')[0])\n",
        "    visit_id = x.split('_')[0] + '_' + x.split('_')[1]\n",
        "    # set all predictions 0 where updrs equals 'updrs_4'\n",
        "    if updrs=='updrs_3':\n",
        "#         rating = updrs_3_pred[month]\n",
        "        rating = df[df.visit_id == visit_id]['pred2'].values[0]\n",
        "    elif updrs=='updrs_4':\n",
        "        rating = 0\n",
        "    elif updrs =='updrs_1':\n",
        "        rating = df[df.visit_id == visit_id]['pred0'].values[0]\n",
        "    else:\n",
        "        rating = df[df.visit_id == visit_id]['pred1'].values[0]\n",
        "    return rating\n",
        "\n",
        "counter = 0\n",
        "# The API will deliver four dataframes in this specific order:\n",
        "for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n",
        "    df = test[['visit_id']].drop_duplicates('visit_id')\n",
        "    pred_0 = features(df[['visit_id']], test_proteins, test_peptides, 0)\n",
        "    scale_col = ['NPX_min','NPX_max','NPX_mean','NPX_std', 'Abe_min', 'Abe_max', 'Abe_mean', 'Abe_std']\n",
        "    pred_0[scale_col] = mms.fit_transform(pred_0[scale_col])\n",
        "    pred_0 = model[0].predict(pred_0.drop(columns = ['visit_id'], axis = 1))\n",
        "    df['pred0'] = np.ceil(pred_0)\n",
        "\n",
        "    pred_1 = features(df[['visit_id']], test_proteins, test_peptides, 1)\n",
        "    scale_col = ['NPX_min','NPX_max','NPX_mean','NPX_std', 'Abe_min', 'Abe_max', 'Abe_mean', 'Abe_std']\n",
        "    pred_1[scale_col] = mms.fit_transform(pred_1[scale_col])\n",
        "    pred_1 = model[1].predict(pred_1.drop(columns = ['visit_id'], axis = 1))\n",
        "    df['pred1'] = np.ceil(pred_1)\n",
        "\n",
        "    pred_2 = features(df[['visit_id']], test_proteins, test_peptides, 2)\n",
        "    scale_col = ['NPX_min','NPX_max','NPX_mean','NPX_std', 'Abe_min', 'Abe_max', 'Abe_mean', 'Abe_std']\n",
        "    pred_2[scale_col] = mms.fit_transform(pred_2[scale_col])\n",
        "    pred_2 = model[2].predict(pred_2.drop(columns = ['visit_id'], axis = 1))\n",
        "    df['pred2'] = np.ceil(pred_2)\n",
        "\n",
        "    sample_submission['rating'] = sample_submission['prediction_id'].apply(map_test)\n",
        "    env.predict(sample_submission)\n",
        "\n",
        "    if counter == 0:\n",
        "        display(test)\n",
        "        display(sample_submission)\n",
        "\n",
        "    counter += 1\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}